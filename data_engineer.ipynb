{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/Grades.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take all rows of the first 12 columns\n",
    "\n",
    "df = df.iloc[:, :12]\n",
    "df.columns = ['Song', 'Album', 'Happy/Sad', 'Relationship', 'Feelings of self', 'Glass half full', 'Stages', 'Tempo', 'Seriousness', 'Future prospects', 'Feelings of male', 'Togetherness']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(axis=0).reset_index(drop=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/Grades_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = [\n",
    "    'anger.txt',\n",
    "    'fear.txt',\n",
    "    'joy.txt',\n",
    "    'sadness.txt'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "path = 'training'\n",
    "\n",
    "for file in file_name:\n",
    "    df = pd.read_csv(f'data/emoint_2017/{path}/{file}', sep='\\t', header=None)\n",
    "    df.columns = ['id', 'text', 'emotion', 'intensity']\n",
    "    \n",
    "    dfs.append(df)\n",
    "\n",
    "training_data = pd.concat(dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted_training = pd.pivot_table(training_data, index='text', values='intensity', columns='emotion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted_training = pivoted_training.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>emotion</th>\n",
       "      <th>anger</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>sadness</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I can't guess if you holding a grudge against the best'</th>\n",
       "      <td>0.425</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th># ISIS REFERENCES SCRUBBED?  Federal complaint against suspect in NYC, NJ bombings appears to omit terror names in bloody journ...  #news</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.729</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#Aleppo city is burning. The head of #terrorism #Assad regime &amp;amp; #Russia are bombarding the city right now with #whitephosphrus #bombs !</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.729</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#Always #borrow #money from a #pessimist. He won't #expect it #back.</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#America finding #gratitude amidst the sadness and frustration about race, #fear, anger and #racism, i remain hopeful _ i'm an earth fixer'</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ï˜« ughh I just want all this to be over.. it's like a nightmare! can we all just get along?</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ðŸ˜± @cailamarsai you've had me ðŸ˜‚ ðŸ˜‚ the whole time watching @black_ishABC after you've lost your #glasses! It was #hilarious! @mrbabyboogaloo</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ðŸ˜³The intensity that @sydneyswans play at is extraordinary #relentless #AFLCatsSwans #AFLFinals ðŸ‰ðŸ‘ðŸ¿</th>\n",
       "      <td>0.292</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ðŸ’¥âš–ï¸Yeahâ€¼ï¸ PAULâ€¼ï¸âš–ï¸ðŸ’¥  #glorious #BB18</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ðŸ”¥Anger is the acid that can do more harm to the vessel in which it is stored than to anything on which it is poured.ðŸ”¥ #anger \\n\\n~Mark Twain</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3565 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "emotion                                             anger   fear    joy  \\\n",
       "text                                                                      \n",
       " I can't guess if you holding a grudge against ...  0.425  0.000  0.000   \n",
       "# ISIS REFERENCES SCRUBBED?  Federal complaint ...  0.000  0.729  0.000   \n",
       "#Aleppo city is burning. The head of #terrorism...  0.000  0.729  0.000   \n",
       "#Always #borrow #money from a #pessimist. He wo...  0.000  0.000  0.000   \n",
       "#America finding #gratitude amidst the sadness ...  0.000  0.583  0.000   \n",
       "...                                                   ...    ...    ...   \n",
       "ï˜« ughh I just want all this to be over.. it's...  0.000  0.797  0.000   \n",
       "ðŸ˜± @cailamarsai you've had me ðŸ˜‚ ðŸ˜‚ the w...  0.000  0.000  0.900   \n",
       "ðŸ˜³The intensity that @sydneyswans play at is ...  0.292  0.000  0.000   \n",
       "ðŸ’¥âš–ï¸Yeahâ€¼ï¸ PAULâ€¼ï¸âš–ï¸ðŸ’¥  #glo...  0.000  0.000  0.917   \n",
       "ðŸ”¥Anger is the acid that can do more harm to ...  0.500  0.000  0.000   \n",
       "\n",
       "emotion                                             sadness  \n",
       "text                                                         \n",
       " I can't guess if you holding a grudge against ...    0.000  \n",
       "# ISIS REFERENCES SCRUBBED?  Federal complaint ...    0.000  \n",
       "#Aleppo city is burning. The head of #terrorism...    0.000  \n",
       "#Always #borrow #money from a #pessimist. He wo...    0.354  \n",
       "#America finding #gratitude amidst the sadness ...    0.000  \n",
       "...                                                     ...  \n",
       "ï˜« ughh I just want all this to be over.. it's...    0.000  \n",
       "ðŸ˜± @cailamarsai you've had me ðŸ˜‚ ðŸ˜‚ the w...    0.000  \n",
       "ðŸ˜³The intensity that @sydneyswans play at is ...    0.000  \n",
       "ðŸ’¥âš–ï¸Yeahâ€¼ï¸ PAULâ€¼ï¸âš–ï¸ðŸ’¥  #glo...    0.000  \n",
       "ðŸ”¥Anger is the acid that can do more harm to ...    0.000  \n",
       "\n",
       "[3565 rows x 4 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivoted_training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Development data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dfs = []\n",
    "\n",
    "path = 'development'\n",
    "\n",
    "for file in file_name:\n",
    "    df = pd.read_csv(f'data/emoint_2017/{path}/{file}', sep='\\t', header=None)\n",
    "    df.columns = ['id', 'text', 'emotion', 'intensity']\n",
    "    \n",
    "    dfs.append(df)\n",
    "\n",
    "dev_data = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted_dev = pd.pivot_table(dev_data, index='text', values='intensity', columns='emotion')\n",
    "\n",
    "pivoted_dev = pivoted_dev.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dfs = []\n",
    "\n",
    "path = 'test'\n",
    "\n",
    "for file in file_name:\n",
    "    df = pd.read_csv(f'data/emoint_2017/{path}/{file}', sep='\\t', header=None)\n",
    "    df.columns = ['id', 'text', 'emotion', 'intensity']\n",
    "    \n",
    "    dfs.append(df)\n",
    "\n",
    "test_data = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted_test = pd.pivot_table(test_data, index='text', values='intensity', columns='emotion')\n",
    "pivoted_test = pivoted_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted_training.to_csv('data/emoint_2017/emoint_training.csv')\n",
    "pivoted_dev.to_csv('data/emoint_2017/emoint_dev.csv')\n",
    "pivoted_test.to_csv('data/emoint_2017/emoint_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/emotion_nlp/val.txt', sep=';', header=None)\n",
    "df.columns = ['text', 'emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby(['text', 'emotion']).size().unstack(fill_value=0)\n",
    "df.to_csv('data/cleaned_data/emotion_nlp_val.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/emotion_nlp/test.txt', sep=';', header=None)\n",
    "df.columns = ['text', 'emotion']\n",
    "df = df.groupby(['text', 'emotion']).size().unstack(fill_value=0)\n",
    "df.to_csv('data/cleaned_data/emotion_nlp_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/emotion_nlp/train.txt', sep=';', header=None)\n",
    "df.columns = ['text', 'emotion']\n",
    "df = df.groupby(['text', 'emotion']).size().unstack(fill_value=0)\n",
    "df.to_csv('data/cleaned_data/emotion_nlp_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KAGGLE EMOTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/kaggle_emotion.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].replace({0:'sadness', 1:'joy', 2:'love', 3:'anger', 4:'fear', 5:'surprise'}, inplace=True)\n",
    "df = df.groupby(['text', 'label']).size().unstack(fill_value=0)\n",
    "\n",
    "df.to_csv('data/cleaned_data/kaggle_emotion.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAMPLE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/cleaned_data/emoint_test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(300, replace=False).to_csv('data/cleaned_data/emoint_test_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(1000, replace=False).to_csv('data/cleaned_data/emoint_test_1000_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(3000, replace=False).to_csv('data/cleaned_data/emoint_test_3000_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/cleaned_data/kaggle_emotion.csv', index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(300, replace=False).to_csv('data/cleaned_data/kaggle_emotion_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(1000, replace=False).to_csv('data/cleaned_data/kaggle_emotion_1000_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(3000, replace=False).to_csv('data/cleaned_data/kaggle_emotion_3000_sample.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEW SHOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/cleaned_data/emoint_test_sample.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df = df.sample(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[0.0, 0.0, 0.562, 0.0]'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'['+', '.join(sampled_df.iloc[0].astype(str).values)+']'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
